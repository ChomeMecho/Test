{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hypernetworks_in_keras_and_tf2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChomeMecho/Test/blob/master/Hypernetworks_in_keras_and_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA6CfJ159Qke"
      },
      "source": [
        "#Guide to Hypernetworks in Keras and Tensorflow 2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFscRdMm4-R_"
      },
      "source": [
        "This is a keras implementation of hypernetworks, which are typically a pair of networks where one generates the parameters (weights) of the other [(Ha, et al., 2016)](https://arxiv.org/abs/1609.09106). Keras layer implementation exposes the parameters of a layer as two modifiable properties: ‘kernel’ and ‘bias’, which allows assiging them new values during inference.\n",
        "\n",
        "This code will separate the hypernetwork into two keras models: an inference model which will perform the inference task  (for e.g. classify handwritten digits), and a hyper model, which will generate the parameters of the inference model for each input example. We will demonstrate using a convolutional network as the inference model to classify MNIST digits.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHUHlg3PpsFq",
        "outputId": "d1efd541-b064-4e26-b54c-a40639dd01ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tf-nightly-gpu-2.0-preview"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-nightly-gpu-2.0-preview\n",
            "  Downloading tf-nightly-gpu-2-0-preview-0.0.0.1.tar.gz (1.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tf-nightly-gpu-2.0-preview\n",
            "  Building wheel for tf-nightly-gpu-2.0-preview (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tf-nightly-gpu-2.0-preview: filename=tf_nightly_gpu_2_0_preview-0.0.0.1-py3-none-any.whl size=1542 sha256=eedf9da89db2a99c572a3a7c743a2da378b76d9dfdefcb53fb53f25a3ae8500d\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/c6/2e/5b35865ca6234c39a564b7803e8105a8050cb66121a475b27c\n",
            "Successfully built tf-nightly-gpu-2.0-preview\n",
            "Installing collected packages: tf-nightly-gpu-2.0-preview\n",
            "Successfully installed tf-nightly-gpu-2.0-preview-0.0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnNVpdnU94fi",
        "outputId": "e6631248-0e18-41c1-969a-db3be9c7637d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Import tensorflow and check version\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('tensorflow version: {}'.format(tf.__version__))\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version: 2.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAd3QYjg-AjH"
      },
      "source": [
        "For this tutorial will use the MNIST dataset to demonstrate the setup. The following code will download and prepare the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVQYaADmbd7Y",
        "outputId": "0398f045-4adf-4ccb-8097-5eeafad5a43c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# convert to float32 and normalize.\n",
        "x_train = x_train.astype('float32') /255\n",
        "x_test = x_test.astype('float32')   /255\n",
        "\n",
        "# one-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "# add a channel dimension to the images\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28,1)\n",
        "\n",
        "\n",
        "# Define image dimensions\n",
        "img_h = 28\n",
        "img_w = 28\n",
        "img_c = 1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIPU7Szr-tU_"
      },
      "source": [
        "### Inference model:\n",
        "We now build the inference model, a simple convolutional network, with a fully connected layer on top, that we will use to classify MNIST digits.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkMNzey0-uQb",
        "outputId": "3a19c5c1-8599-44f7-8726-939326fc7d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "infer_model = tf.keras.models.Sequential(name='infer_model')\n",
        "infer_model.add(tf.keras.layers.Input(shape=(img_h, img_w, img_c), name='input_x' ))\n",
        "infer_model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu') )\n",
        "infer_model.add(tf.keras.layers.MaxPool2D() )\n",
        "infer_model.add(tf.keras.layers.Conv2D(32, (3,3), activation='relu') )\n",
        "infer_model.add(tf.keras.layers.MaxPool2D() )\n",
        "infer_model.add(tf.keras.layers.Flatten() )\n",
        "\n",
        "infer_model.add(tf.keras.layers.Dense(10, activation= 'softmax', name='out_layer') )\n",
        "\n",
        "infer_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"infer_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"infer_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ out_layer (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m8,010\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ out_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,010</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,578\u001b[0m (68.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,578</span> (68.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,578\u001b[0m (68.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,578</span> (68.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2irt-_gV-r0z"
      },
      "source": [
        "Note that this model has a total of 17,578 parameters that need to be generated by the hyper model.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uFLUlgxEFbq"
      },
      "source": [
        "### Hyper model:\n",
        "Let us now define the hyper model with 2 convolutional layers and a fully connected layer on top to produce a latent embedding of size 784. The embedding is then fed into a stack of 3 transpose convolutional layers that produce a large number of values, which will be used as parameters for the inference model.\n",
        "\n",
        "Note that the last layer uses a tanh activation function which produces values between -1 and 1. This allows generation of parameters with negative values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obmi-YOfEUhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988f4294-1ed7-4b70-9bbb-484bcab23129"
      },
      "source": [
        "hyper_model_x = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.InputLayer(input_shape=(img_h, img_w, img_c)),\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu') ,\n",
        "        tf.keras.layers.MaxPool2D() ,\n",
        "        tf.keras.layers.Conv2D(8, (3,3), activation='relu') ,\n",
        "        tf.keras.layers.MaxPool2D() ,\n",
        "        tf.keras.layers.Flatten() ,\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(units=784, activation=tf.nn.relu),\n",
        "        tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.Conv2DTranspose(\n",
        "            filters=16,\n",
        "            kernel_size=3,\n",
        "            strides=(2, 2),\n",
        "            padding=\"same\",\n",
        "            activation=tf.nn.relu),\n",
        "        tf.keras.layers.Conv2DTranspose(\n",
        "            filters=8,\n",
        "            kernel_size=3,\n",
        "            strides=(2, 2),\n",
        "            padding=\"same\",\n",
        "            activation=tf.nn.relu),\n",
        "        tf.keras.layers.Conv2DTranspose(\n",
        "            filters=2, kernel_size=3, strides=(1, 1), padding=\"SAME\", activation='tanh'),\n",
        "        tf.keras.layers.Flatten()\n",
        "    ], name='hyper_model'\n",
        ")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVoEllG5FSzY"
      },
      "source": [
        "To apply parameters to the inference model, we define a function 'parametrize_model', which consumes a tensor of generated parameters to parametrize the weights and the biases of each layer in a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA4OJzYqJR-Y"
      },
      "source": [
        "def parameterize_model(model, weights):\n",
        "    # function to parametrizes all the trainable variables of model using the stream of weight values in weights\n",
        "    # This assumes weights are passed a single batch.\n",
        "    weights = tf.reshape( weights, [-1] ) # reshape the parameters to a vector\n",
        "\n",
        "    last_used = 0\n",
        "    for i in range(len(model.layers)):\n",
        "        # check to make sure only conv and fully connected layers are assigned weights.\n",
        "        if 'conv' in model.layers[i].name or 'out' in model.layers[i].name or 'dense' in model.layers[i].name:\n",
        "            weights_shape = model.layers[i].kernel.shape\n",
        "            no_of_weights = tf.reduce_prod(weights_shape)\n",
        "            new_weights = tf.reshape(weights[last_used:last_used+no_of_weights], weights_shape)\n",
        "            model.layers[i].kernel = new_weights\n",
        "            last_used += no_of_weights\n",
        "\n",
        "            if model.layers[i].use_bias:\n",
        "              weights_shape = model.layers[i].bias.shape\n",
        "              no_of_weights = tf.reduce_prod(weights_shape)\n",
        "              new_weights = tf.reshape(weights[last_used:last_used+no_of_weights], weights_shape)\n",
        "              model.layers[i].bias = new_weights\n",
        "              last_used += no_of_weights\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7n5JgFfIInp"
      },
      "source": [
        "### The training loop:\n",
        "We are now ready to define the main training loop. Eager execution is enabled by default in tensorflow 2.0, which provides more control over the training process. Note that the loss function is differentiated with respect to the hyper model parameters only. In fact, the parameters of the inference model are no longer considered trainable by keras (can check by running infer_model.summary()). This loop updates the parameters of the hyper model only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLgoCcsLqNQ1",
        "outputId": "5d4244fc-4404-468d-b779-20b7fa21f841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "# Define accuracy metrics for validation\n",
        "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "loss_accum = 0.0\n",
        "batch_size = 1\n",
        "for step in range(1, 6001):\n",
        "  idx = np.random.randint(low=0, high=x_train.shape[0], size=batch_size)\n",
        "  x, y = x_train[idx], y_train[idx]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Predict weights for the infer model\n",
        "    generated_parameters = hyper_model_x(x)\n",
        "    parameterize_model(infer_model, generated_parameters)\n",
        "\n",
        "    # Inference on the infer model\n",
        "    preds = infer_model(x)\n",
        "\n",
        "    loss = loss_fn( y, preds)\n",
        "    loss_accum += loss\n",
        "    train_acc_metric( y, tf.expand_dims(preds, 0)) # update the acc metric\n",
        "\n",
        "    if step % 1000 == 0:\n",
        "      loss_accum = 0.0\n",
        "      var = generated_parameters.numpy()\n",
        "      print('statistics of the generated parameters: '+'Mean, {:2.3f}, var {:2.3f}, min {:2.3f}, max {:2.3f}'.format(var.mean(), var.var(), var.min(), var.max()))\n",
        "      for val_step in range(500): #\n",
        "        idx = np.random.randint(low=0, high=x_test.shape[0], size=batch_size)\n",
        "        x, y = x_test[idx], y_test[idx]\n",
        "        generated_parameters = hyper_model_x(x)\n",
        "        parameterize_model(infer_model, generated_parameters)\n",
        "        preds = infer_model(x)\n",
        "        val_acc_metric( y, tf.expand_dims(preds, 0)) # update the acc metric\n",
        "      print('\\n Step: {}, validation set accuracy: {:2.2f}     loss: {:2.2f}'.format(step, float(val_acc_metric.result()), loss_accum))\n",
        "      val_acc_metric.reset_states()\n",
        "\n",
        "\n",
        "    # Train only hyper model\n",
        "    grads = tape.gradient(loss, hyper_model_x.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, hyper_model_x.trainable_weights))\n",
        "\n",
        ""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "can't set attribute 'kernel'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e9d82426682e>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Predict weights for the infer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mgenerated_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyper_model_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mparameterize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfer_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Inference on the infer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-bb5fa2ad999b>\u001b[0m in \u001b[0;36mparameterize_model\u001b[0;34m(model, weights)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mno_of_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mnew_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlast_used\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mno_of_weights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mlast_used\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mno_of_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_tracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trackable.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mtrackable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             )\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/autotrackable.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m     68\u001b[0m       value = data_structures.sticky_attribute_assignment(\n\u001b[1;32m     69\u001b[0m           trackable=self, value=value, name=name)\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: can't set attribute 'kernel'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcnIhobpqunK"
      },
      "source": [
        "Two issues arise in building a hypernetwork in keras. First is managing mini-batching to speed up training on GPUs, and the second relates to initializing the weights.\n",
        "The need for a different weight matrix for each input sample introduces significant challenges in using mini-batches during training. While it is possible to create custom keras layers that can handle storing a batch of weights and biases for each layer, we kept batch_size at 1 for the purposes of this tutorial.\n",
        "On another front, the intial values of a neural network parameters may significantly impact training dynamics. Keras, by default, uses the [Glorot initializer ](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf), which factors in the number of connections coming from previous layers. In a hypernetwork setup, assigning weights directly to a network sidesteps this initilaization that keras normally handles automatically. Accordingly, it is important to moniter and the statistics of the generated parameters and consider how their mean, variance and range might affect training dynamics. For the purposes of this guide, we found it important to use a tanh activation function in the last layer of the hyper model, which provided values cenetered around 0 with a range from -1 to 1.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha6mGmQKivqO"
      },
      "source": [
        "Finally let's look at a histogram of the generated parameters. There is a sharp peak around very small negative values  around -0.1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6p9Wf3TKeOh"
      },
      "source": [
        "_ = plt.hist(generated_parameters, bins=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFiPFx9OjiWh"
      },
      "source": [
        "####References:\n",
        "1) Ha, D., Dai, A., & Le, Q. V. (2016). Hypernetworks. arXiv preprint arXiv:1609.09106.\n",
        "    \n",
        "2) Glorot, X. & Bengio, Y.. (2010). Understanding the difficulty of training deep feedforward neural networks. Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, in PMLR 9:249-256\n"
      ]
    }
  ]
}